{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/kushal/.local/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/lib/python3/dist-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/kushal/.local/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/kushal/.local/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/kushal/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/kushal/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/kushal/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kushal/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in /home/kushal/.local/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/kushal/.local/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/kushal/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/kushal/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/kushal/.local/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/kushal/.local/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/kushal/.local/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/kushal/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/kushal/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/kushal/.local/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kushal/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1553972540.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python -m spacy download en_core_web_sm\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing document: /home/kushal/Documents/aiml/regulations/REGULATION (EU) GDPR.txt\n",
      "\n",
      "Processing document: /home/kushal/Documents/aiml/regulations/PCI_DSS_v2_Cloud_Guidelines.txt\n",
      "\n",
      "Extraction completed. Clauses saved to extracted_clauses.txt\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from pathlib import Path\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define keywords to filter sentences\n",
    "keywords = [\"log\", \"retention\", \"incident\", \"audit\", \"report\", \"breach\", \"compliance\"]\n",
    "\n",
    "# Directory containing regulatory documents\n",
    "document_dir = \"/home/kushal/Documents/aiml/regulations\"  # Replace with the path to your documents folder\n",
    "\n",
    "# Create a function to process each document\n",
    "def extract_clauses(file_path):\n",
    "    print(f\"\\nProcessing document: {file_path}\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract sentences containing the keywords\n",
    "    extracted_clauses = []\n",
    "    for sent in doc.sents:\n",
    "        if any(keyword in sent.text.lower() for keyword in keywords):\n",
    "            extracted_clauses.append(sent.text.strip())\n",
    "\n",
    "    return extracted_clauses\n",
    "\n",
    "# Iterate over all documents in the folder\n",
    "all_clauses = {}\n",
    "for file_path in Path(document_dir).glob(\"*.txt\"):  # Assuming .txt files for simplicity\n",
    "    clauses = extract_clauses(file_path)\n",
    "    all_clauses[file_path.name] = clauses\n",
    "\n",
    "# Save the extracted clauses to an output file\n",
    "output_file = \"extracted_clauses.txt\"\n",
    "with open(output_file, 'w', encoding='utf-8') as out:\n",
    "    for doc_name, clauses in all_clauses.items():\n",
    "        out.write(f\"Document: {doc_name}\\n\")\n",
    "        out.write(\"\\n\".join(f\"- {clause}\" for clause in clauses))\n",
    "        out.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"\\nExtraction completed. Clauses saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to generated_survey_analysis.txt\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define keywords to filter sentences\n",
    "keywords = [\"log\", \"encryption\", \"retention\", \"incident\", \"access\", \"compliance\", \"audit\", \"monitoring\"]\n",
    "\n",
    "# CSP responses\n",
    "generated_responses = \"\"\"\n",
    "AWS: Logs are securely encrypted and stored with tamper-proof mechanisms. Retention periods can be customized.\n",
    "Azure: Provides detailed incident reporting and integrates monitoring with role-based access controls (RBAC).\n",
    "GCP: Offers automated alerts for anomaly detection and supports compliance with GDPR, HIPAA, and PCI DSS.\n",
    "IBM Cloud: Includes audit-ready compliance templates for GDPR and provides multi-year log retention options.\n",
    "Oracle Cloud: Ensures data integrity through encryption and offers advanced access control mechanisms.\n",
    "Alibaba Cloud: Logs are retained for five years by default and encrypted to ensure data security.\n",
    "\"\"\"\n",
    "\n",
    "# Output file to save extracted insights\n",
    "output_file = \"generated_survey_analysis.txt\"\n",
    "\n",
    "def extract_key_points(text):\n",
    "    \"\"\"Extract key points from the given text based on keywords.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    extracted_sentences = []\n",
    "    for sent in doc.sents:\n",
    "        if any(keyword in sent.text.lower() for keyword in keywords):\n",
    "            extracted_sentences.append(sent.text.strip())\n",
    "    return extracted_sentences\n",
    "\n",
    "def analyze_generated_responses(responses, output_file):\n",
    "    \"\"\"Process the CSP responses and save insights to a file.\"\"\"\n",
    "    # Extract key points\n",
    "    key_points = extract_key_points(responses)\n",
    "    \n",
    "    # Write the results to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        out_file.write(\"Extracted Key Points from CSP Responses:\\n\\n\")\n",
    "        for point in key_points:\n",
    "            out_file.write(f\"- {point}\\n\")\n",
    "    \n",
    "    print(f\"Analysis complete. Results saved to {output_file}\")\n",
    "\n",
    "# Analyze the generated responses\n",
    "analyze_generated_responses(generated_responses, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='system_logs.json', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "def log_event(event_type, description, user=None, ip_address=None):\n",
    "    \"\"\"Log an event with relevant details.\"\"\"\n",
    "    event = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"event_type\": event_type,\n",
    "        \"description\": description,\n",
    "        \"user\": user,\n",
    "        \"ip_address\": ip_address\n",
    "    }\n",
    "    logging.info(json.dumps(event))\n",
    "\n",
    "# Example log entries\n",
    "log_event(\"LOGIN_ATTEMPT\", \"User attempted to log in\", user=\"user1\", ip_address=\"192.168.1.1\")\n",
    "log_event(\"LOGIN_SUCCESS\", \"User logged in successfully\", user=\"user1\", ip_address=\"192.168.1.1\")\n",
    "log_event(\"ACCESS_DENIED\", \"Unauthorized access attempt\", ip_address=\"10.0.0.5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Simulated login attempt data (e.g., number of failed logins per user per hour)\n",
    "data = np.array([[0], [1], [0], [10], [0], [15], [0]])  # Normal: 0-1, Anomalous: >10\n",
    "\n",
    "# Train an Isolation Forest model\n",
    "model = IsolationForest(contamination=0.2, random_state=42)\n",
    "model.fit(data)\n",
    "\n",
    "# Predict anomalies\n",
    "predictions = model.predict(data)  # -1: anomaly, 1: normal\n",
    "\n",
    "# Display results\n",
    "for i, (value, prediction) in enumerate(zip(data.flatten(), predictions)):\n",
    "    status = \"Anomaly\" if prediction == -1 else \"Normal\"\n",
    "    print(f\"Data Point {i}: Value = {value}, Status = {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptography.fernet import Fernet\n",
    "import json\n",
    "\n",
    "# Generate and save an encryption key\n",
    "key = Fernet.generate_key()\n",
    "with open(\"encryption_key.key\", \"wb\") as key_file:\n",
    "    key_file.write(key)\n",
    "\n",
    "# Load the encryption key\n",
    "with open(\"encryption_key.key\", \"rb\") as key_file:\n",
    "    key = key_file.read()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Encrypt a log entry\n",
    "log_entry = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat(),\n",
    "    \"event_type\": \"LOGIN_FAILURE\",\n",
    "    \"description\": \"Failed login attempt\",\n",
    "    \"user\": \"user2\",\n",
    "    \"ip_address\": \"192.168.1.2\"\n",
    "}\n",
    "log_data = json.dumps(log_entry).encode()\n",
    "encrypted_log = cipher_suite.encrypt(log_data)\n",
    "\n",
    "# Save encrypted log to a file\n",
    "with open(\"encrypted_logs.txt\", \"wb\") as log_file:\n",
    "    log_file.write(encrypted_log)\n",
    "\n",
    "# Decrypt the log entry for verification\n",
    "with open(\"encrypted_logs.txt\", \"rb\") as log_file:\n",
    "    encrypted_log = log_file.read()\n",
    "decrypted_log = cipher_suite.decrypt(encrypted_log)\n",
    "print(\"Decrypted Log:\", decrypted_log.decode())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compliance_requirements = {\n",
    "    \"GDPR\": [\"Logs must be retained for 1 year\", \"Data breaches reported within 72 hours\"],\n",
    "    \"HIPAA\": [\"Logs retained for 6 years\", \"Access controls implemented\"],\n",
    "    \"PCI DSS\": [\"Logs must be encrypted\", \"Access to logs must be monitored\"]\n",
    "}\n",
    "\n",
    "framework_features = {\n",
    "    \"Retention Policy\": \"Logs retained for 6 years\",\n",
    "    \"Incident Response\": \"Breaches reported within 72 hours\",\n",
    "    \"Encryption\": \"Logs encrypted with AES-256\",\n",
    "    \"Access Control\": \"RBAC implemented\"\n",
    "}\n",
    "\n",
    "def check_compliance(requirements, features):\n",
    "    results = {}\n",
    "    for regulation, reqs in requirements.items():\n",
    "        compliance = [req for req in reqs if req in features.values()]\n",
    "        results[regulation] = {\n",
    "            \"Compliant\": compliance,\n",
    "            \"Non-Compliant\": [req for req in reqs if req not in compliance]\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Perform compliance check\n",
    "results = check_compliance(compliance_requirements, framework_features)\n",
    "for regulation, result in results.items():\n",
    "    print(f\"{regulation} Compliance:\")\n",
    "    print(f\"  Compliant: {result['Compliant']}\")\n",
    "    print(f\"  Non-Compliant: {result['Non-Compliant']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "from cryptography.fernet import Fernet\n",
    "\n",
    "# --- Configuration ---\n",
    "# Logging configuration\n",
    "logging.basicConfig(filename='system_logs.json', level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# Encryption setup\n",
    "key = Fernet.generate_key()\n",
    "cipher_suite = Fernet(key)\n",
    "\n",
    "# Keywords for anomaly detection\n",
    "keywords = [\"log\", \"encryption\", \"retention\", \"incident\", \"access\", \"compliance\", \"audit\", \"monitoring\"]\n",
    "\n",
    "# Compliance requirements\n",
    "compliance_requirements = {\n",
    "    \"GDPR\": [\"Logs must be retained for 1 year\", \"Data breaches reported within 72 hours\"],\n",
    "    \"HIPAA\": [\"Logs retained for 6 years\", \"Access controls implemented\"],\n",
    "    \"PCI DSS\": [\"Logs must be encrypted\", \"Access to logs must be monitored\"]\n",
    "}\n",
    "\n",
    "# Framework features\n",
    "framework_features = {\n",
    "    \"Retention Policy\": \"Logs retained for 6 years\",\n",
    "    \"Incident Response\": \"Breaches reported within 72 hours\",\n",
    "    \"Encryption\": \"Logs encrypted with AES-256\",\n",
    "    \"Access Control\": \"RBAC implemented\"\n",
    "}\n",
    "\n",
    "# --- Functions ---\n",
    "def log_event(event_type, description, user=None, ip_address=None):\n",
    "    \"\"\"Log an event with relevant details.\"\"\"\n",
    "    event = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"event_type\": event_type,\n",
    "        \"description\": description,\n",
    "        \"user\": user,\n",
    "        \"ip_address\": ip_address\n",
    "    }\n",
    "    logging.info(json.dumps(event))\n",
    "    return event\n",
    "\n",
    "def encrypt_log_entry(log_entry):\n",
    "    \"\"\"Encrypt a log entry.\"\"\"\n",
    "    log_data = json.dumps(log_entry).encode()\n",
    "    encrypted_log = cipher_suite.encrypt(log_data)\n",
    "    return encrypted_log\n",
    "\n",
    "def anomaly_detection(data):\n",
    "    \"\"\"Detect anomalies in the data using Isolation Forest.\"\"\"\n",
    "    model = IsolationForest(contamination=0.2, random_state=42)\n",
    "    model.fit(data)\n",
    "    predictions = model.predict(data)\n",
    "    return predictions\n",
    "\n",
    "def check_compliance(requirements, features):\n",
    "    \"\"\"Check compliance of framework features against requirements.\"\"\"\n",
    "    results = {}\n",
    "    for regulation, reqs in requirements.items():\n",
    "        compliance = [req for req in reqs if req in features.values()]\n",
    "        results[regulation] = {\n",
    "            \"Compliant\": compliance,\n",
    "            \"Non-Compliant\": [req for req in reqs if req not in compliance]\n",
    "        }\n",
    "    return results\n",
    "\n",
    "def generate_incident_report(anomaly_index, data_point, description=\"Anomalous behavior detected\"):\n",
    "    \"\"\"Generate an incident report.\"\"\"\n",
    "    report = {\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"incident_id\": f\"INC-{anomaly_index+1:03}\",\n",
    "        \"description\": description,\n",
    "        \"data_point\": data_point.tolist()\n",
    "    }\n",
    "    with open(\"incident_reports.json\", \"a\") as report_file:\n",
    "        report_file.write(json.dumps(report) + \"\\n\")\n",
    "    print(f\"Incident Report Generated: {report}\")\n",
    "    return report\n",
    "\n",
    "def access_logs(user, role, access_level=\"read\"):\n",
    "    \"\"\"Simulate RBAC for log access.\"\"\"\n",
    "    roles_permissions = {\n",
    "        \"admin\": [\"read\", \"write\", \"delete\"],\n",
    "        \"auditor\": [\"read\"],\n",
    "        \"user\": [\"read\"]\n",
    "    }\n",
    "    if access_level not in roles_permissions.get(role, []):\n",
    "        print(f\"Access Denied for {user} with role {role} and access level {access_level}.\")\n",
    "        return False\n",
    "    print(f\"Access Granted for {user} with role {role} and access level {access_level}.\")\n",
    "    return True\n",
    "\n",
    "# --- System Execution ---\n",
    "def run_forensic_readiness_framework():\n",
    "    # Step 1: Logging Events\n",
    "    print(\"\\nStep 1: Logging Events...\")\n",
    "    events = [\n",
    "        log_event(\"LOGIN_ATTEMPT\", \"User attempted to log in\", user=\"user1\", ip_address=\"192.168.1.1\"),\n",
    "        log_event(\"LOGIN_SUCCESS\", \"User logged in successfully\", user=\"user1\", ip_address=\"192.168.1.1\"),\n",
    "        log_event(\"ACCESS_DENIED\", \"Unauthorized access attempt\", ip_address=\"10.0.0.5\"),\n",
    "    ]\n",
    "\n",
    "    # Step 2: Encrypt Logs\n",
    "    print(\"\\nStep 2: Encrypting Logs...\")\n",
    "    encrypted_logs = [encrypt_log_entry(event) for event in events]\n",
    "    with open(\"encrypted_logs.txt\", \"wb\") as log_file:\n",
    "        for enc_log in encrypted_logs:\n",
    "            log_file.write(enc_log + b'\\n')\n",
    "    print(\"Encrypted logs saved to 'encrypted_logs.txt'.\")\n",
    "\n",
    "    # Step 3: Detect Anomalies\n",
    "    print(\"\\nStep 3: Detecting Anomalies...\")\n",
    "    login_attempts = np.array([[0], [1], [0], [10], [0], [15], [0]])  # Simulated data\n",
    "    anomalies = anomaly_detection(login_attempts)\n",
    "    for i, status in enumerate(anomalies):\n",
    "        if status == -1:  # Anomaly detected\n",
    "            generate_incident_report(i, login_attempts[i])\n",
    "\n",
    "    # Step 4: Check Compliance\n",
    "    print(\"\\nStep 4: Checking Compliance...\")\n",
    "    compliance_results = check_compliance(compliance_requirements, framework_features)\n",
    "    for regulation, result in compliance_results.items():\n",
    "        print(f\"\\n{regulation} Compliance:\")\n",
    "        print(f\"  Compliant: {result['Compliant']}\")\n",
    "        print(f\"  Non-Compliant: {result['Non-Compliant']}\")\n",
    "\n",
    "    # Step 5: Access Logs via RBAC\n",
    "    print(\"\\nStep 5: Simulating RBAC...\")\n",
    "    access_logs(\"admin_user\", \"admin\", \"read\")\n",
    "    access_logs(\"auditor_user\", \"auditor\", \"delete\")\n",
    "    access_logs(\"regular_user\", \"user\", \"read\")\n",
    "\n",
    "# Run the system\n",
    "if __name__ == \"__main__\":\n",
    "    run_forensic_readiness_framework()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
